# Repository for LLM Concepts

Welcome to the repository designed for teaching various aspects of working with large language models (LLMs). This repository contains organized content, examples, and practical exercises to help students understand foundational and advanced LLM concepts, from fine-tuning to reinforcement learning.

---

## Repository Structure

### Day 1: Retrieval-Augmented Generation (RAG)
- **Purpose**: Learn how to use external knowledge bases to improve language model responses.
- **Key Files**:
  - `reranking.ipynb`: Notebook for demonstrating RAG concepts with reranking.
  - `text_for_reranking.txt`: Example text data for reranking exercises.
- **Dependencies**: See `requirements.txt` for necessary libraries.

### Day 2: Fine-Tuning
- **Purpose**: Understand the process of adapting a language model to a specific dataset or task.
- **Key Files**:
  - `README.md`: Detailed instructions for exercises.

### Day 3: Reinforcement Learning with Human Feedback (RLHF)
- **Purpose**: Explore RLHF to align language models with human preferences.
- **Key Files**:
  - `rag_evaluation.ipynb`: Notebook for evaluation exercises.
  - `requirements.txt`: Library dependencies.

### Day 4: Agent Optimization
- **Purpose**: Learn to use agents for optimization and task automation.
- **Key Files**:
  - `inline_agent.ipynb`: Demonstrates the creation and optimization of agents.
  - `requirements.txt`: Dependencies for running the notebook.

### Project
- **Purpose**: A capstone project consolidating all the concepts.
- **Key Files**:
  - `vanilla_project`: Example or template for project work.
  - `requirements.txt`: Required libraries.

---


## Prerequisites
- Python 3.8 or higher
- Jupyter Notebook or JupyterLab
- Familiarity with basic Python programming and machine learning concepts