{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring your RAG applications using LLM Observability and RAGAS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datadog's LLM Observability tool allows you to perform evaluations on your LLM application and tie these evaluations to specific traces.\n",
    "\n",
    "In the following example, we'll build and trace a RAG-powered application using [LlamaIndex](https://docs.llamaindex.ai/en/latest/). We'll plug in retrieval and augmented generation strategies to our RAG app and evaluate these different strategies using [RAGAS](https://docs.ragas.io/en/stable/concepts/index.html).\n",
    "\n",
    "#### Learning Goals\n",
    "\n",
    "- Understand how to instrument a RAG-powered LLM application\n",
    "- Understand how to submit custom evaluations tied to specific traces for an LLM application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a Virtual Environment\n",
    "At the root of the folder, in your terminal enter the following\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv .venv & source .venv/bin/activate\n",
    "\n",
    "    ```\n",
    "\n",
    "2. Create an .env file in the RLHF folder withe the following:\n",
    "    ```bash\n",
    "    AWS_ACCESS_KEY_ID=''\n",
    "    AWS_SECRET_ACCESS_KEY=''\n",
    "    AWS_SESSION_TOKEN='' #If needed\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make sure you've followed the setup directions in the README. Then, install LlamaIndex, which we'll use to build our RAG workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv --quiet\n",
    "%pip install ddtrace --quiet\n",
    "%pip install llama-index-embeddings-bedrock --quiet\n",
    "%pip install llama-index-llms-bedrock --quiet\n",
    "%pip install llama-index-core --quiet\n",
    "%pip install ragas --quiet\n",
    "%pip install langchain_aws --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare your knowledge base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the raw Markdown documents and convert them to LlamaIndex nodes, which represent chunks of our source Markdown documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.core import Document\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "folder_path = \"mdfiles\"  # Replace with the actual path if different\n",
    "\n",
    "raw_doc_texts = []\n",
    "\n",
    "# Iterate through all files in the specified folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".md\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            markdown_content = file.read()\n",
    "        raw_doc_texts.append(\n",
    "            Document(text=markdown_content, metadata={\"filename\": filename})\n",
    "        )\n",
    "\n",
    "parser = MarkdownNodeParser()\n",
    "base_nodes = parser.get_nodes_from_documents(raw_doc_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a baseline retriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, initialize a baseline retriever that fetches the top-k raw text nodes based on embedding similarity to an input query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.bedrock import BedrockEmbedding\n",
    "\n",
    "model = BedrockEmbedding(\n",
    "    model_name=\"cohere.embed-multilingual-v3\",\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    aws_session_token=os.getenv(\"AWS_SESSION_TOKEN\"),\n",
    "    region_name=\"eu-west-3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0024032593,\n",
       " 0.04425049,\n",
       " 0.020706177,\n",
       " 0.0036125183,\n",
       " -0.011230469,\n",
       " -0.0006656647,\n",
       " -0.021835327,\n",
       " -0.046081543,\n",
       " -0.04989624,\n",
       " 0.016723633,\n",
       " 0.031036377,\n",
       " -0.016723633,\n",
       " 0.016052246,\n",
       " -0.0047836304,\n",
       " 0.021087646,\n",
       " -0.02684021,\n",
       " 0.037963867,\n",
       " 0.036102295,\n",
       " 0.07531738,\n",
       " 0.0103302,\n",
       " 0.0061454773,\n",
       " -0.029129028,\n",
       " -0.0013151169,\n",
       " -0.061279297,\n",
       " -0.0017910004,\n",
       " 0.0028762817,\n",
       " 0.031082153,\n",
       " -0.012611389,\n",
       " 0.0037651062,\n",
       " -0.0057411194,\n",
       " -0.037384033,\n",
       " -0.008285522,\n",
       " 0.09698486,\n",
       " 0.008125305,\n",
       " -0.01335144,\n",
       " -0.003791809,\n",
       " -0.018157959,\n",
       " -0.03289795,\n",
       " 0.008666992,\n",
       " 0.05529785,\n",
       " -0.008743286,\n",
       " 0.013832092,\n",
       " -0.0076293945,\n",
       " 0.039916992,\n",
       " -0.039886475,\n",
       " -0.0062408447,\n",
       " 0.032440186,\n",
       " 0.029434204,\n",
       " -0.0037879944,\n",
       " 0.05621338,\n",
       " -0.03201294,\n",
       " -0.005794525,\n",
       " 0.019180298,\n",
       " 0.009384155,\n",
       " 0.028289795,\n",
       " -0.013504028,\n",
       " 0.033599854,\n",
       " -0.0178833,\n",
       " 0.03829956,\n",
       " 0.030426025,\n",
       " -0.006996155,\n",
       " -0.05505371,\n",
       " -0.04171753,\n",
       " -0.02229309,\n",
       " 0.024017334,\n",
       " 0.035949707,\n",
       " 0.017181396,\n",
       " 0.024429321,\n",
       " 0.010147095,\n",
       " 0.019119263,\n",
       " 0.0032348633,\n",
       " -0.0009689331,\n",
       " 0.042266846,\n",
       " 0.000872612,\n",
       " -0.030776978,\n",
       " -0.0047836304,\n",
       " 0.028823853,\n",
       " 0.052734375,\n",
       " 0.022247314,\n",
       " 0.036193848,\n",
       " -0.009033203,\n",
       " 0.022369385,\n",
       " 0.033843994,\n",
       " 0.02935791,\n",
       " 0.00579834,\n",
       " 0.012840271,\n",
       " -0.031677246,\n",
       " 0.025909424,\n",
       " 0.016159058,\n",
       " -0.024368286,\n",
       " 0.026977539,\n",
       " 0.04385376,\n",
       " 0.03463745,\n",
       " -0.007888794,\n",
       " 0.01663208,\n",
       " -0.029403687,\n",
       " 0.054138184,\n",
       " -0.039855957,\n",
       " 0.015022278,\n",
       " -0.04623413,\n",
       " -0.0413208,\n",
       " -0.04547119,\n",
       " -0.016296387,\n",
       " -0.0046691895,\n",
       " -0.013420105,\n",
       " -0.005924225,\n",
       " -0.014663696,\n",
       " -0.016098022,\n",
       " -0.053100586,\n",
       " -0.00944519,\n",
       " 0.007751465,\n",
       " 0.027420044,\n",
       " -0.012359619,\n",
       " -0.010520935,\n",
       " -0.06365967,\n",
       " -0.037841797,\n",
       " -0.0029945374,\n",
       " -0.024536133,\n",
       " -0.032073975,\n",
       " -0.07348633,\n",
       " -0.01574707,\n",
       " 0.021270752,\n",
       " -0.0025177002,\n",
       " -0.010375977,\n",
       " -0.031951904,\n",
       " -0.016235352,\n",
       " 0.036987305,\n",
       " 0.0003671646,\n",
       " -0.0033912659,\n",
       " -0.0041046143,\n",
       " -0.03756714,\n",
       " 0.005256653,\n",
       " 0.0051994324,\n",
       " 0.0007982254,\n",
       " 0.030548096,\n",
       " -0.0058898926,\n",
       " -0.015213013,\n",
       " -0.025299072,\n",
       " 0.018493652,\n",
       " -0.022781372,\n",
       " 0.027191162,\n",
       " 0.0018081665,\n",
       " 0.019363403,\n",
       " 0.016113281,\n",
       " -0.047912598,\n",
       " -0.02029419,\n",
       " 0.0625,\n",
       " 0.01776123,\n",
       " 0.015396118,\n",
       " -0.029525757,\n",
       " -0.00075149536,\n",
       " 0.02357483,\n",
       " 0.03842163,\n",
       " -0.025405884,\n",
       " -0.014793396,\n",
       " 0.017303467,\n",
       " 0.021591187,\n",
       " -0.0062561035,\n",
       " -0.016662598,\n",
       " 0.026031494,\n",
       " -0.0029201508,\n",
       " -0.029067993,\n",
       " -0.011444092,\n",
       " -0.025344849,\n",
       " -0.03112793,\n",
       " -0.010482788,\n",
       " 0.06149292,\n",
       " -0.0032920837,\n",
       " -0.0035705566,\n",
       " 0.016433716,\n",
       " 0.02645874,\n",
       " -0.046203613,\n",
       " -0.026733398,\n",
       " -0.018829346,\n",
       " -0.030029297,\n",
       " -0.02986145,\n",
       " 0.0007324219,\n",
       " 0.0119018555,\n",
       " 0.01651001,\n",
       " -0.060333252,\n",
       " 0.017333984,\n",
       " 0.0003247261,\n",
       " -0.016082764,\n",
       " 0.050476074,\n",
       " 0.068603516,\n",
       " 0.03164673,\n",
       " -0.011665344,\n",
       " 0.01109314,\n",
       " -0.010398865,\n",
       " 0.046966553,\n",
       " -0.03564453,\n",
       " -0.07080078,\n",
       " -0.08831787,\n",
       " 0.04107666,\n",
       " -0.008834839,\n",
       " 0.017669678,\n",
       " 0.043060303,\n",
       " -0.06304932,\n",
       " 0.062042236,\n",
       " 0.097595215,\n",
       " 0.011680603,\n",
       " -0.0038146973,\n",
       " 0.02482605,\n",
       " 0.02420044,\n",
       " -0.008834839,\n",
       " 0.016159058,\n",
       " 0.049041748,\n",
       " -0.014877319,\n",
       " -0.008102417,\n",
       " 0.04373169,\n",
       " -0.0021438599,\n",
       " 0.06530762,\n",
       " 0.0124435425,\n",
       " 0.017120361,\n",
       " -0.048583984,\n",
       " -0.042388916,\n",
       " -0.0043563843,\n",
       " -0.037322998,\n",
       " 0.03265381,\n",
       " 0.0602417,\n",
       " 0.07714844,\n",
       " -0.004081726,\n",
       " 0.043273926,\n",
       " 0.03543091,\n",
       " -0.0284729,\n",
       " -0.04611206,\n",
       " 0.03161621,\n",
       " 0.012863159,\n",
       " -0.03439331,\n",
       " -0.037963867,\n",
       " -0.013259888,\n",
       " -0.03540039,\n",
       " -0.008613586,\n",
       " 0.029312134,\n",
       " 0.005622864,\n",
       " 0.024993896,\n",
       " -0.07763672,\n",
       " -0.026367188,\n",
       " -0.06903076,\n",
       " -0.0031013489,\n",
       " 0.008728027,\n",
       " 0.023223877,\n",
       " 0.0036296844,\n",
       " -0.005683899,\n",
       " 0.019058228,\n",
       " 0.004295349,\n",
       " -0.0016613007,\n",
       " -0.012290955,\n",
       " 0.049865723,\n",
       " -0.03933716,\n",
       " 0.00024604797,\n",
       " 0.030227661,\n",
       " -0.024032593,\n",
       " 0.022140503,\n",
       " -0.011680603,\n",
       " -0.032806396,\n",
       " 0.0066986084,\n",
       " -0.025939941,\n",
       " -0.015472412,\n",
       " -0.011672974,\n",
       " -0.01133728,\n",
       " -0.00078105927,\n",
       " 0.026245117,\n",
       " -0.02470398,\n",
       " -0.016403198,\n",
       " -0.011268616,\n",
       " -0.010223389,\n",
       " 0.0033721924,\n",
       " 0.014022827,\n",
       " -0.005519867,\n",
       " -0.016326904,\n",
       " -0.0005607605,\n",
       " -0.051727295,\n",
       " 0.088378906,\n",
       " 0.03930664,\n",
       " 0.037841797,\n",
       " -0.042297363,\n",
       " 0.020080566,\n",
       " -0.031311035,\n",
       " 0.045654297,\n",
       " 0.036071777,\n",
       " -0.003364563,\n",
       " 0.009353638,\n",
       " 0.016326904,\n",
       " -0.04989624,\n",
       " 0.004524231,\n",
       " -0.039367676,\n",
       " 0.01637268,\n",
       " -0.018127441,\n",
       " 0.006175995,\n",
       " -0.011070251,\n",
       " -0.015930176,\n",
       " -0.021392822,\n",
       " 0.022994995,\n",
       " -0.013458252,\n",
       " -0.0042381287,\n",
       " 0.0052871704,\n",
       " -0.022521973,\n",
       " -0.01826477,\n",
       " 0.007949829,\n",
       " -0.028213501,\n",
       " 0.031066895,\n",
       " 0.03326416,\n",
       " -0.020187378,\n",
       " 0.01234436,\n",
       " 0.072143555,\n",
       " 0.03186035,\n",
       " 0.012809753,\n",
       " 0.07354736,\n",
       " 0.027923584,\n",
       " -0.011772156,\n",
       " -0.0034217834,\n",
       " -0.018478394,\n",
       " -0.012306213,\n",
       " -0.013572693,\n",
       " -0.0137786865,\n",
       " -0.047302246,\n",
       " -0.039154053,\n",
       " 0.016723633,\n",
       " 0.048217773,\n",
       " -0.0059432983,\n",
       " -0.03982544,\n",
       " -0.018920898,\n",
       " -0.02557373,\n",
       " -0.027008057,\n",
       " 0.028900146,\n",
       " 0.0018920898,\n",
       " -0.020965576,\n",
       " 0.004638672,\n",
       " 0.011390686,\n",
       " -0.035827637,\n",
       " 0.014129639,\n",
       " 0.01789856,\n",
       " -0.01864624,\n",
       " 0.040924072,\n",
       " 0.03387451,\n",
       " 0.033233643,\n",
       " 0.030014038,\n",
       " 0.037200928,\n",
       " -0.041809082,\n",
       " 0.012962341,\n",
       " 0.018218994,\n",
       " -0.013404846,\n",
       " -0.010345459,\n",
       " 0.032043457,\n",
       " 0.031311035,\n",
       " 0.015197754,\n",
       " -0.036010742,\n",
       " -0.08276367,\n",
       " -0.07952881,\n",
       " 0.02859497,\n",
       " 0.0284729,\n",
       " -0.049621582,\n",
       " 0.0036563873,\n",
       " 0.009803772,\n",
       " -0.024749756,\n",
       " -0.026260376,\n",
       " -0.010772705,\n",
       " 0.0029697418,\n",
       " -0.038024902,\n",
       " 0.02053833,\n",
       " -0.06964111,\n",
       " -0.018371582,\n",
       " 0.0032920837,\n",
       " -0.022354126,\n",
       " 0.032226562,\n",
       " 0.0020008087,\n",
       " 0.014640808,\n",
       " -0.043182373,\n",
       " -0.0053977966,\n",
       " 0.044921875,\n",
       " -0.011367798,\n",
       " 0.055389404,\n",
       " 0.06262207,\n",
       " -0.061279297,\n",
       " 0.030944824,\n",
       " -0.040649414,\n",
       " -0.01953125,\n",
       " -0.01979065,\n",
       " 0.0039482117,\n",
       " 0.044311523,\n",
       " 0.04046631,\n",
       " -0.074157715,\n",
       " 0.07757568,\n",
       " 0.029922485,\n",
       " 0.0014629364,\n",
       " -0.0043525696,\n",
       " -0.013023376,\n",
       " -0.0024986267,\n",
       " 0.010658264,\n",
       " 0.0491333,\n",
       " 0.02507019,\n",
       " 0.0050354004,\n",
       " 0.033447266,\n",
       " 0.00856781,\n",
       " 0.02029419,\n",
       " -0.025283813,\n",
       " 0.017868042,\n",
       " -0.02609253,\n",
       " -0.015914917,\n",
       " 0.015838623,\n",
       " -0.062805176,\n",
       " -0.009155273,\n",
       " -0.053375244,\n",
       " 0.03942871,\n",
       " 0.0110321045,\n",
       " -0.025512695,\n",
       " 0.006034851,\n",
       " -0.0056610107,\n",
       " 0.00012207031,\n",
       " -0.032348633,\n",
       " 0.0057411194,\n",
       " -0.015197754,\n",
       " 0.0070381165,\n",
       " -0.022247314,\n",
       " -0.008453369,\n",
       " -0.015838623,\n",
       " 0.04144287,\n",
       " -0.042816162,\n",
       " -0.013946533,\n",
       " -0.018554688,\n",
       " -0.014266968,\n",
       " -0.017196655,\n",
       " -0.00083732605,\n",
       " 0.015640259,\n",
       " 0.0016288757,\n",
       " 0.016098022,\n",
       " -0.007911682,\n",
       " 0.05847168,\n",
       " 0.013908386,\n",
       " 0.021942139,\n",
       " -0.0046424866,\n",
       " -0.009170532,\n",
       " -0.015205383,\n",
       " -0.029571533,\n",
       " -0.011459351,\n",
       " -0.061065674,\n",
       " 0.020996094,\n",
       " -0.011550903,\n",
       " 0.040222168,\n",
       " 0.0031261444,\n",
       " 0.0001411438,\n",
       " 0.037017822,\n",
       " 0.005874634,\n",
       " 0.06500244,\n",
       " 0.013008118,\n",
       " -0.009819031,\n",
       " 0.025146484,\n",
       " -0.03741455,\n",
       " -0.0028762817,\n",
       " 0.008857727,\n",
       " 0.006893158,\n",
       " 0.00017166138,\n",
       " -0.03036499,\n",
       " 0.018798828,\n",
       " -0.031021118,\n",
       " -0.0056877136,\n",
       " 0.029525757,\n",
       " -0.04437256,\n",
       " 0.0037193298,\n",
       " -0.05319214,\n",
       " 0.0064888,\n",
       " 0.040374756,\n",
       " -0.029174805,\n",
       " 0.0418396,\n",
       " -0.033599854,\n",
       " -0.029724121,\n",
       " 0.01966858,\n",
       " 0.009864807,\n",
       " 0.0129852295,\n",
       " -0.045532227,\n",
       " 0.061523438,\n",
       " -0.027359009,\n",
       " -0.035949707,\n",
       " 0.031585693,\n",
       " 0.062347412,\n",
       " -0.027420044,\n",
       " 0.017868042,\n",
       " 0.0052337646,\n",
       " 0.03149414,\n",
       " -0.035064697,\n",
       " 0.013282776,\n",
       " 0.017623901,\n",
       " 0.0009460449,\n",
       " -0.032470703,\n",
       " 0.026062012,\n",
       " 0.04699707,\n",
       " 0.0009460449,\n",
       " 0.095703125,\n",
       " -0.02458191,\n",
       " 0.0099487305,\n",
       " 0.0121154785,\n",
       " -0.0635376,\n",
       " -0.017410278,\n",
       " 0.026367188,\n",
       " -0.055358887,\n",
       " 0.023986816,\n",
       " -0.04095459,\n",
       " -0.0335083,\n",
       " -0.02053833,\n",
       " 0.0680542,\n",
       " 0.017349243,\n",
       " -0.004760742,\n",
       " 0.0048828125,\n",
       " -0.011405945,\n",
       " 0.018096924,\n",
       " 0.023971558,\n",
       " -0.012359619,\n",
       " 0.026168823,\n",
       " 0.05822754,\n",
       " -0.026779175,\n",
       " -0.024932861,\n",
       " -0.040283203,\n",
       " 0.029785156,\n",
       " -0.016082764,\n",
       " -0.06060791,\n",
       " 0.011940002,\n",
       " 0.053222656,\n",
       " 0.0236969,\n",
       " -0.041381836,\n",
       " 0.0021133423,\n",
       " 0.026046753,\n",
       " -0.0018806458,\n",
       " -0.0058135986,\n",
       " 0.021331787,\n",
       " 0.0014762878,\n",
       " -0.04953003,\n",
       " 0.031433105,\n",
       " -0.07208252,\n",
       " 0.021453857,\n",
       " -0.020233154,\n",
       " 0.00033187866,\n",
       " -0.029785156,\n",
       " -0.015533447,\n",
       " -0.034210205,\n",
       " -0.11407471,\n",
       " 0.031082153,\n",
       " 0.016113281,\n",
       " 0.0289917,\n",
       " 0.07556152,\n",
       " 0.058166504,\n",
       " -0.0026054382,\n",
       " 0.053588867,\n",
       " 0.02508545,\n",
       " 0.0079956055,\n",
       " -0.040924072,\n",
       " -0.02494812,\n",
       " -0.05480957,\n",
       " -0.021621704,\n",
       " 0.039855957,\n",
       " 0.0029335022,\n",
       " 0.0020065308,\n",
       " -0.01335907,\n",
       " -0.02494812,\n",
       " 0.014877319,\n",
       " 0.011009216,\n",
       " -0.055480957,\n",
       " -0.01574707,\n",
       " 0.029266357,\n",
       " -0.008224487,\n",
       " 0.044403076,\n",
       " -0.11663818,\n",
       " -0.0034675598,\n",
       " 0.059387207,\n",
       " -0.027954102,\n",
       " -7.05719e-05,\n",
       " -0.02659607,\n",
       " 0.007499695,\n",
       " 0.01083374,\n",
       " -0.068603516,\n",
       " 0.01512146,\n",
       " 0.052978516,\n",
       " 0.020950317,\n",
       " -0.00034332275,\n",
       " -0.019805908,\n",
       " -0.023635864,\n",
       " 0.04067993,\n",
       " 0.0034637451,\n",
       " -0.034729004,\n",
       " -0.018203735,\n",
       " -0.0034809113,\n",
       " 0.025909424,\n",
       " 0.016036987,\n",
       " -0.008255005,\n",
       " -0.057403564,\n",
       " -0.07647705,\n",
       " 0.03060913,\n",
       " 0.012298584,\n",
       " 0.037902832,\n",
       " -0.0098724365,\n",
       " 0.046447754,\n",
       " -0.023162842,\n",
       " 0.028671265,\n",
       " 0.050445557,\n",
       " -0.0027008057,\n",
       " 0.005378723,\n",
       " 0.00039863586,\n",
       " 0.045776367,\n",
       " 0.044769287,\n",
       " -0.002521515,\n",
       " -0.018096924,\n",
       " 0.0042419434,\n",
       " -0.0052986145,\n",
       " 0.0067367554,\n",
       " 0.005317688,\n",
       " 0.0016326904,\n",
       " 0.028839111,\n",
       " 0.0040664673,\n",
       " 0.01423645,\n",
       " 0.024871826,\n",
       " 0.010734558,\n",
       " 0.009666443,\n",
       " 0.07727051,\n",
       " -0.00484848,\n",
       " -1.335144e-05,\n",
       " -0.032318115,\n",
       " -0.06939697,\n",
       " 0.011856079,\n",
       " 0.014060974,\n",
       " 0.040985107,\n",
       " -0.074279785,\n",
       " 0.019989014,\n",
       " -0.018814087,\n",
       " -0.0109939575,\n",
       " -0.0357666,\n",
       " 0.034973145,\n",
       " 0.10522461,\n",
       " -0.04360962,\n",
       " -0.045410156,\n",
       " -0.0082473755,\n",
       " -0.016540527,\n",
       " -0.070495605,\n",
       " 0.001619339,\n",
       " -0.018707275,\n",
       " 0.012817383,\n",
       " -0.012039185,\n",
       " -0.032318115,\n",
       " -0.055480957,\n",
       " -0.038970947,\n",
       " 0.0018367767,\n",
       " -0.0072631836,\n",
       " -0.01663208,\n",
       " 0.038116455,\n",
       " -0.019058228,\n",
       " -0.012512207,\n",
       " -0.05633545,\n",
       " -0.024276733,\n",
       " -0.02848816,\n",
       " -0.0357666,\n",
       " 0.012535095,\n",
       " 0.033996582,\n",
       " -0.054748535,\n",
       " -0.006008148,\n",
       " -0.022583008,\n",
       " -0.0061836243,\n",
       " 0.048706055,\n",
       " 0.041046143,\n",
       " 0.035308838,\n",
       " -0.02557373,\n",
       " 0.05596924,\n",
       " -0.0013141632,\n",
       " -0.008148193,\n",
       " 0.000541687,\n",
       " 0.018005371,\n",
       " -0.0052871704,\n",
       " 0.03540039,\n",
       " -0.022094727,\n",
       " 0.027648926,\n",
       " 0.015792847,\n",
       " -0.047790527,\n",
       " -0.002937317,\n",
       " 0.020507812,\n",
       " 0.03201294,\n",
       " 0.03643799,\n",
       " 0.049926758,\n",
       " -0.008262634,\n",
       " -0.054229736,\n",
       " -0.05999756,\n",
       " -0.0032596588,\n",
       " -0.030395508,\n",
       " -0.007019043,\n",
       " 0.05343628,\n",
       " -0.025650024,\n",
       " -0.0073509216,\n",
       " 0.0050086975,\n",
       " 0.002735138,\n",
       " -0.0715332,\n",
       " -0.068725586,\n",
       " -0.012580872,\n",
       " -0.019958496,\n",
       " -0.0015048981,\n",
       " 0.07965088,\n",
       " 0.03186035,\n",
       " 0.020935059,\n",
       " -0.010856628,\n",
       " 0.040252686,\n",
       " 0.03149414,\n",
       " 0.008758545,\n",
       " -0.03378296,\n",
       " 0.03616333,\n",
       " -0.029815674,\n",
       " 0.061676025,\n",
       " 0.024932861,\n",
       " 0.016342163,\n",
       " 0.005607605,\n",
       " -0.0127334595,\n",
       " 0.040527344,\n",
       " -0.03286743,\n",
       " -0.031951904,\n",
       " 0.00091934204,\n",
       " -0.019378662,\n",
       " 0.0052948,\n",
       " 0.008728027,\n",
       " 0.0016880035,\n",
       " -0.020248413,\n",
       " 0.03842163,\n",
       " 0.019805908,\n",
       " 0.017700195,\n",
       " -0.020690918,\n",
       " 0.04324341,\n",
       " -0.024810791,\n",
       " 0.0035934448,\n",
       " 0.01423645,\n",
       " -0.038269043,\n",
       " 0.007865906,\n",
       " -0.011016846,\n",
       " -0.009841919,\n",
       " 0.0071144104,\n",
       " -0.019546509,\n",
       " 0.015274048,\n",
       " -0.0032043457,\n",
       " 0.027770996,\n",
       " 0.0015306473,\n",
       " 0.000333786,\n",
       " -0.009475708,\n",
       " -0.00969696,\n",
       " -0.060272217,\n",
       " -0.07897949,\n",
       " 0.061431885,\n",
       " -0.04425049,\n",
       " 0.0385437,\n",
       " 0.035064697,\n",
       " 0.011405945,\n",
       " -0.04260254,\n",
       " -0.0038986206,\n",
       " 0.023864746,\n",
       " -0.028137207,\n",
       " 0.05303955,\n",
       " -0.042633057,\n",
       " -0.014152527,\n",
       " 0.005569458,\n",
       " 0.06878662,\n",
       " 0.025878906,\n",
       " 0.0017299652,\n",
       " -0.017562866,\n",
       " -0.01940918,\n",
       " 0.012741089,\n",
       " 0.013824463,\n",
       " -0.029174805,\n",
       " -0.0008468628,\n",
       " -0.0066184998,\n",
       " -0.0013923645,\n",
       " -0.0104904175,\n",
       " -0.016296387,\n",
       " -0.013381958,\n",
       " 0.024749756,\n",
       " 0.009544373,\n",
       " -0.01751709,\n",
       " -0.015838623,\n",
       " 0.0066871643,\n",
       " -0.0031642914,\n",
       " -0.0006942749,\n",
       " 0.018478394,\n",
       " -0.014335632,\n",
       " 0.013687134,\n",
       " 0.028198242,\n",
       " -0.017501831,\n",
       " 0.021133423,\n",
       " 0.02468872,\n",
       " -0.002336502,\n",
       " -0.0077056885,\n",
       " -0.005908966,\n",
       " 0.009765625,\n",
       " -0.017089844,\n",
       " 0.0054855347,\n",
       " 0.005870819,\n",
       " 0.04559326,\n",
       " 0.015274048,\n",
       " 0.02407837,\n",
       " 0.018081665,\n",
       " -0.012672424,\n",
       " -0.005744934,\n",
       " 0.016143799,\n",
       " -0.04949951,\n",
       " -0.010559082,\n",
       " 0.00655365,\n",
       " 0.03778076,\n",
       " -0.009170532,\n",
       " 0.014350891,\n",
       " -0.05166626,\n",
       " 0.077941895,\n",
       " -0.03289795,\n",
       " -0.010688782,\n",
       " -0.004737854,\n",
       " -0.030456543,\n",
       " -0.03225708,\n",
       " -0.02281189,\n",
       " 0.039855957,\n",
       " -0.009429932,\n",
       " 0.015556335,\n",
       " -0.04736328,\n",
       " 0.05834961,\n",
       " -0.020904541,\n",
       " -0.01374054,\n",
       " 0.01033783,\n",
       " -0.008354187,\n",
       " 0.030334473,\n",
       " 0.039886475,\n",
       " -0.009498596,\n",
       " 0.01889038,\n",
       " -0.040252686,\n",
       " 0.0025997162,\n",
       " -0.018081665,\n",
       " -0.019119263,\n",
       " 0.024398804,\n",
       " 0.018737793,\n",
       " 0.020263672,\n",
       " 0.0052223206,\n",
       " -0.016448975,\n",
       " 0.008148193,\n",
       " -0.05065918,\n",
       " -0.0069389343,\n",
       " -0.0043754578,\n",
       " 0.009246826,\n",
       " 0.00667572,\n",
       " -0.012924194,\n",
       " 0.017852783,\n",
       " 0.047546387,\n",
       " -0.0008029938,\n",
       " -0.0030059814,\n",
       " 0.0067749023,\n",
       " -0.005428314,\n",
       " 0.00982666,\n",
       " -0.0069351196,\n",
       " 0.027999878,\n",
       " 0.026153564,\n",
       " -0.036346436,\n",
       " 0.080322266,\n",
       " -0.01802063,\n",
       " 0.07873535,\n",
       " -0.008682251,\n",
       " 0.008300781,\n",
       " 0.017089844,\n",
       " -0.0074005127,\n",
       " -0.0025463104,\n",
       " -0.015342712,\n",
       " -0.036254883,\n",
       " 0.023803711,\n",
       " 0.03262329,\n",
       " 0.024505615,\n",
       " 0.0022010803,\n",
       " -0.026916504,\n",
       " 0.0070724487,\n",
       " -0.0051879883,\n",
       " 0.020935059,\n",
       " 0.010803223,\n",
       " -0.0072402954,\n",
       " 0.021347046,\n",
       " 0.039733887,\n",
       " -0.013999939,\n",
       " -0.001209259,\n",
       " -0.00793457,\n",
       " 0.00045871735,\n",
       " -0.064819336,\n",
       " 0.04168701,\n",
       " 0.016082764,\n",
       " 0.018844604,\n",
       " 0.007446289,\n",
       " 0.013923645,\n",
       " 0.06149292,\n",
       " 0.027313232,\n",
       " -0.035461426,\n",
       " 0.005191803,\n",
       " -0.03656006,\n",
       " 0.022201538,\n",
       " -0.02607727,\n",
       " -0.023803711,\n",
       " 0.05670166,\n",
       " -0.030792236,\n",
       " 0.023040771,\n",
       " -0.010681152,\n",
       " 0.005432129,\n",
       " -0.0026893616,\n",
       " -0.0033073425,\n",
       " -0.034729004,\n",
       " 0.05279541,\n",
       " 0.057556152,\n",
       " -0.023284912,\n",
       " -0.04107666,\n",
       " -0.0005302429,\n",
       " -0.034820557,\n",
       " -0.025848389,\n",
       " 0.035095215,\n",
       " -0.0103302,\n",
       " 0.0056533813,\n",
       " -0.021362305,\n",
       " 0.06262207,\n",
       " 0.009155273,\n",
       " 0.011505127,\n",
       " 0.009094238,\n",
       " -0.022857666,\n",
       " 0.04916382,\n",
       " 0.0041007996,\n",
       " 0.04171753,\n",
       " -0.0019798279,\n",
       " -0.008728027,\n",
       " -0.009979248,\n",
       " 0.04699707,\n",
       " -0.050354004,\n",
       " -0.015609741,\n",
       " -0.030731201,\n",
       " 0.049041748,\n",
       " -0.015525818,\n",
       " 0.006668091,\n",
       " -0.040802002,\n",
       " -0.04763794,\n",
       " 0.010253906,\n",
       " 0.033325195,\n",
       " -0.013748169,\n",
       " -0.005077362,\n",
       " -0.024658203,\n",
       " 0.019546509,\n",
       " 0.018615723,\n",
       " -0.02330017,\n",
       " -0.017333984,\n",
       " -0.015617371,\n",
       " 0.008125305,\n",
       " -0.0033569336,\n",
       " 0.03036499,\n",
       " -0.0061798096,\n",
       " 0.027694702,\n",
       " 0.021514893,\n",
       " -0.013061523,\n",
       " -0.03152466,\n",
       " 0.00033712387,\n",
       " 0.017608643,\n",
       " -0.028076172,\n",
       " 0.024795532,\n",
       " 0.002588272,\n",
       " -0.0262146,\n",
       " 0.04171753,\n",
       " -0.015037537,\n",
       " 0.024307251,\n",
       " -0.019210815,\n",
       " -0.01878357,\n",
       " 0.0013370514,\n",
       " 0.005531311,\n",
       " 0.0015411377,\n",
       " 0.020385742,\n",
       " 0.00283432,\n",
       " -0.046295166,\n",
       " 0.041290283,\n",
       " 0.0077209473,\n",
       " 0.020202637,\n",
       " -0.04244995,\n",
       " 0.010749817,\n",
       " 0.06774902,\n",
       " -0.045928955,\n",
       " -0.0042266846,\n",
       " 0.074401855,\n",
       " 0.028442383,\n",
       " 0.039489746,\n",
       " -0.06738281,\n",
       " -0.009925842,\n",
       " -0.033081055,\n",
       " 0.01234436,\n",
       " -0.019821167,\n",
       " 0.047668457,\n",
       " 0.036071777,\n",
       " 0.0062675476,\n",
       " 0.0048828125,\n",
       " -0.03173828,\n",
       " 0.03878784,\n",
       " 0.0134887695,\n",
       " 0.013641357,\n",
       " 0.014045715,\n",
       " 0.06365967,\n",
       " -0.022583008,\n",
       " 0.022338867,\n",
       " -0.033233643,\n",
       " -0.013114929,\n",
       " -0.016525269,\n",
       " -0.042877197,\n",
       " -0.060272217,\n",
       " -0.008804321,\n",
       " 0.06774902,\n",
       " 0.007865906,\n",
       " -0.012260437,\n",
       " 0.041992188,\n",
       " 0.02357483,\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "model.get_text_embedding(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 2\n",
    "base_index = VectorStoreIndex(base_nodes, embed_model=model)\n",
    "base_retriever = base_index.as_retriever(similarity_top_k=TOP_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a response synthesizer to help generate the answer to a question based on retrieved context documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.llms.bedrock.base import Bedrock\n",
    "\n",
    "llm = Bedrock(\n",
    "    model=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    aws_session_token=os.getenv(\"AWS_SESSION_TOKEN\"),\n",
    "    region_name=\"eu-west-3\",\n",
    "    temperature=0,\n",
    "    max_tokens=3000,\n",
    ")\n",
    "\n",
    "response_synthesizer_compact = get_response_synthesizer(\n",
    "    response_mode=ResponseMode.COMPACT, llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a `retrieve_nodes` function that uses the `base_retriever` to fetch the most relevant context documents given a query. We'll also define an `ask_docs` workflow that combines the retrieval and augmented generation step to return a final answer for a given query.\n",
    "\n",
    "To instrument the retrieval step, we\n",
    "\n",
    "- Decorate the `retrieve_nodes` step with the `retrieval` decorator.\n",
    "- Annotate the span's `input_data` as the input query.\n",
    "- Annotate the span's `output_data` as a list of dictionaries which each represent a single chunk.\n",
    "- Annotate the span's `metadata` with our `top_k` setting.\n",
    "- Tag our retrieval step with the retriever we are using\n",
    "\n",
    "Note that we also return the result of `LLMObs.export_span()` at the end of the `ask_docs` function. We'll need the exported span for later when we submit evaluation results to Datadog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_nodes(query, retriever=base_retriever):\n",
    "    nodes = retriever.retrieve(query)\n",
    "    return nodes\n",
    "\n",
    "\n",
    "def ask_docs(\n",
    "    query, retriever=base_retriever, response_synthesizer=response_synthesizer_compact\n",
    "):\n",
    "    nodes = retrieve_nodes(query, retriever=retriever)\n",
    "    response = response_synthesizer.synthesize(query, nodes=nodes)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our RAG workflow is ready! Try a question about LLM Observability. What do you think of the answer quality?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: AWS Bedrock is a framework that allows you to integrate large language models (LLMs) into your applications. It provides a set of APIs and tools to access and use pre-trained LLMs from various providers, including OpenAI, Anthropic, and Hugging Face. Some key features of AWS Bedrock include:\n",
      "\n",
      "1. Access to a wide range of pre-trained LLMs: AWS Bedrock gives you access to a variety of state-of-the-art LLMs, allowing you to choose the one that best fits your use case.\n",
      "\n",
      "2. Easy integration: The AWS Bedrock SDK provides a simple and consistent interface for interacting with different LLM providers, making it easy to integrate LLMs into your applications.\n",
      "\n",
      "3. Scalability: AWS Bedrock is built on top of AWS infrastructure, allowing you to scale your LLM usage as needed to handle increasing workloads.\n",
      "\n",
      "4. Security and compliance: AWS Bedrock ensures that your LLM usage is secure and compliant with various regulations and standards.\n",
      "\n",
      "5. Monitoring and observability: The LLM Observability SDK for Python, as mentioned in the context, can be used to trace and monitor your LLM usage when using AWS Bedrock, providing valuable insights into latency, errors, and token usage.\n",
      "Context: ['## Use integrations with LLM Observability\\n\\nThe [LLM Observability SDK for Python][3] integrates with frameworks such as OpenAI, LangChain, AWS Bedrock, and Anthropic. It automatically traces and annotate LLM calls, capturing latency, errors, and token usage metrics—without code changes.\\n\\n<div class=\"alert alert-info\">Datadog offers a variety of artificial intelligence (AI) and machine learning (ML) capabilities. The <a href=\"/integrations/#cat-aiml\">AI/ML integrations on the Integrations page and the Datadog Marketplace</a> are platform-wide Datadog functionalities. <br><br> For example, APM offers a native integration with OpenAI for monitoring your OpenAI usage, while Infrastructure Monitoring offers an integration with NVIDIA DCGM Exporter for monitoring compute-intensive AI workloads. These integrations are different from the LLM Observability offering.</div>\\n\\nFor more information, see the [Auto Instrumentation documentation][8].', '## Further Reading\\n\\n{{< partial name=\"whats-next/whats-next.html\" >}}\\n\\n[1]: https://app.datadoghq.com/llm/traces\\n[2]: /llm_observability/terms\\n[3]: /llm_observability/setup/sdk\\n[4]: /llm_observability/setup/api\\n[5]: /llm_observability/setup\\n[6]: /llm_observability/quickstart\\n[7]: https://app.datadoghq.com/dash/integration/llm_operational_insights\\n[8]: /llm_observability/setup/auto_instrumentation']\n"
     ]
    }
   ],
   "source": [
    "STARTER_QUESTION = \"What AWS Bedrock and what are its features?\"\n",
    "\n",
    "answer = ask_docs(STARTER_QUESTION, retriever=base_retriever)\n",
    "\n",
    "print(\"Answer: {}\".format(answer))\n",
    "print(\"Context: {}\".format([reference.text for reference in answer.source_nodes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive retriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement a recursive retriever and plug that into our `ask_docs` workflow.\n",
    "\n",
    "A recursive retriever first builds a graph of small chunks that have references to larger parent chunks. At query-time, smaller chunks are retrieved first, and then we follow references to bigger chunks. This enhances the context we pass to the augmented generation step. For more information on recursive retrieval, see LlamaIndex's [recursive retrieval](https://docs.llamaindex.ai/en/stable/examples/retrievers/recursive_retriever_nodes/) guide.\n",
    "\n",
    "Since our raw documents are in Markdown, there's already an implicit parent-child relationship between different text chunks. LlamaIndex provides helpful utility functions to automatically parse these relationships and form an index that is searchable using their `RecursiveRetriever` module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 1445.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes Created\n",
      "Creating Vector Store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Retriever\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import IndexNode\n",
    "from llama_index.core.retrievers import RecursiveRetriever\n",
    "\n",
    "\n",
    "sub_chunk_sizes = [256, 512]\n",
    "sub_node_parsers = [\n",
    "    SentenceSplitter(chunk_size=c, chunk_overlap=20) for c in sub_chunk_sizes\n",
    "]\n",
    "\n",
    "all_nodes = []\n",
    "for base_node in tqdm(base_nodes):\n",
    "    for n in sub_node_parsers:\n",
    "        sub_nodes = n.get_nodes_from_documents([base_node])\n",
    "        sub_inodes = [\n",
    "            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n",
    "        ]\n",
    "        all_nodes.extend(sub_inodes)\n",
    "\n",
    "    # also add original node to node\n",
    "    original_node = IndexNode.from_text_node(base_node, base_node.node_id)\n",
    "    all_nodes.append(original_node)\n",
    "\n",
    "print(\"Nodes Created\")\n",
    "all_nodes_dict = {n.node_id: n for n in all_nodes}\n",
    "\n",
    "print(\"Creating Vector Store\")\n",
    "vector_index_chunk = VectorStoreIndex(all_nodes, embed_model=model)\n",
    "\n",
    "\n",
    "print(\"Creating Retriever\")\n",
    "vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=TOP_K)\n",
    "\n",
    "recursive_retriever = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the answer improved from our earlier step...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: What AWS Bedrock and what are its features?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: cbddade1-c6f9-483b-8a2f-6e02a746c80b\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id cbddade1-c6f9-483b-8a2f-6e02a746c80b: What AWS Bedrock and what are its features?\n",
      "\u001b[0mAnswer: AWS Bedrock is a managed service that allows you to deploy and run large language models (LLMs) for your applications. Some key features of AWS Bedrock include:\n",
      "\n",
      "1. Managed infrastructure: AWS Bedrock handles the provisioning and scaling of the infrastructure required to run your LLMs, allowing you to focus on building your applications.\n",
      "\n",
      "2. Pre-trained models: AWS Bedrock provides access to a variety of pre-trained LLMs that you can use in your applications, without having to train the models yourself.\n",
      "\n",
      "3. Fine-tuning capabilities: AWS Bedrock allows you to fine-tune the pre-trained models to your specific use case, improving their performance for your application.\n",
      "\n",
      "4. Inference capabilities: AWS Bedrock enables you to perform inference using the LLMs, allowing you to generate text, answer questions, and perform other natural language processing tasks.\n",
      "\n",
      "5. Monitoring and observability: The LLM Observability SDK for Python, as mentioned in the context, can be used to trace and monitor the usage of AWS Bedrock LLMs, providing insights into latency, errors, and token usage.\n",
      "Context: ['## Use integrations with LLM Observability\\n\\nThe [LLM Observability SDK for Python][3] integrates with frameworks such as OpenAI, LangChain, AWS Bedrock, and Anthropic. It automatically traces and annotate LLM calls, capturing latency, errors, and token usage metrics—without code changes.\\n\\n<div class=\"alert alert-info\">Datadog offers a variety of artificial intelligence (AI) and machine learning (ML) capabilities. The <a href=\"/integrations/#cat-aiml\">AI/ML integrations on the Integrations page and the Datadog Marketplace</a> are platform-wide Datadog functionalities. <br><br> For example, APM offers a native integration with OpenAI for monitoring your OpenAI usage, while Infrastructure Monitoring offers an integration with NVIDIA DCGM Exporter for monitoring compute-intensive AI workloads. These integrations are different from the LLM Observability offering.</div>\\n\\nFor more information, see the [Auto Instrumentation documentation][8].']\n"
     ]
    }
   ],
   "source": [
    "answer = ask_docs(STARTER_QUESTION, retriever=recursive_retriever)\n",
    "\n",
    "print(\"Answer: {}\".format(answer))\n",
    "print(\"Context: {}\".format([reference.text for reference in answer.source_nodes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the context differ for our two different retrieval strategies, and ultimately, which response do you think is better?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAGAS Setup\n",
    "\n",
    "Suppose you wanted to deploy both the baseline retriever and recursive retriever and evaluate how well each retrieval strategy is doing in a production environment. Our LLM Observability SDK enables this through the `submit_evaluation` function.\n",
    "\n",
    "As an example, we'll use the RAGAS open source library to evaluate our RAG workflow. It's powered by LLM-assisted evaluations that measure the performance of your retrievals, augmented generation, and RAG workflow end-to-end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll define a list of questions we'll ask our RAG app. Some RAGAS evaluations also require ground truth answers in relation to a target question, so we'll have to define those as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = [\n",
    "    \"How do I get started?\",\n",
    "    \"I have a complex chatbot, what root span should I use to represent this bot?\",\n",
    "    \"I have a summarization LLM service with some simple pre-and-post processing steps, what root span should I use to represent this bot?\",\n",
    "    \"I don't want to manually instrument my app. Can I still use LLM Observability?\",\n",
    "    \"What's the ml app tag?\",\n",
    "    \"How can I enable user session tracking?\",\n",
    "    # \"Is it possible to enable user session tracking via API? If so, how?\",\n",
    "    # \"Do you support distributed tracing?\",\n",
    "    # \"What integrations do you support and how do I enable these integrations?\",\n",
    "    # \"What languages does LLM Observability have SDK's in?\"\n",
    "    # \"If my application is not in the list of supported languages, can I still use LLM Observability?\",\n",
    "    # \"How can I submit evaluations on spans to LLM Observability?\",\n",
    "    # \"What are the different ways to setup the LLM Observability SDK?\",\n",
    "    # \"What's the expected input and output data format for the LLM Span kinds?\",\n",
    "    # \"My app is written is Golang, how do I get started?\",\n",
    "]\n",
    "\n",
    "eval_ground_truths = [\n",
    "    \"To get started with LLM Observability, you can build a simple example with the Quickstart, or follow the guide for instrumenting your LLM application. Make sure to grab your Datadog API Key\",\n",
    "    \"You should use an agent root span to represent your complex chatbot.\",\n",
    "    \"You should use a workflow root span to represent your complex chatbot.\",\n",
    "    \"LLM Observability has supported integrations for openai, bedrock, and langchain and these libraries will automatically be traced\",\n",
    "    \"The name of your LLM application, service, or project, under which all traces and spans are grouped. This helps distinguish between different applications or experiments.\",\n",
    "    \"When starting a root span for a new trace or span in a new process, specify the session_id argument with the string ID of the underlying user session. You can also set the session_id field when submitting spans via API.\",\n",
    "    # \"Yes, you can set the session_id field for a specific span or a top level attribute in SpansPayload.\",\n",
    "    # \"LLM Observability has OpenAI, Bedrock, and LangChain integrations\",\n",
    "    # \"You can submit evaluations to LLM Observability via the SDK's submit_evaluation function or the Evaluations API\",\n",
    "    # \"You can set up the LLM Observability SDK either through the command line and environment variables or purely in-code\",\n",
    "    # \"A list of messages, where each element in the list contains the message content and role.\",\n",
    "    # \"You can instrument your Golang apps via our LLM Observability API. We currently do not have a Golang SDK\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import RAGAS metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    Faithfulness,\n",
    "    ResponseRelevancy,\n",
    "    LLMContextPrecisionWithReference,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to enrich each of the RAGAS metrics with some metadata that will be relevant when we submit results to Datadog.\n",
    "\n",
    "We'll split out RAGAS metrics into two categories - `production` and `dev`.\n",
    "\n",
    "`production` evaluations don't require ground truths to compute the final score, meaning they can be continously run against production data, while `dev` evaluations require a ground truth.\n",
    "\n",
    "We also specify that the metric type is type `score`, which tells Datadog the evaluation metric has the value of a continuous float.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, Callable\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.metrics import (\n",
    "    LLMContextPrecisionWithReference,\n",
    "    Faithfulness,\n",
    "    ResponseRelevancy,\n",
    ")\n",
    "import boto3\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    aws_session_token=os.getenv(\"AWS_SESSION_TOKEN\"),\n",
    "    region_name=\"eu-west-3\",\n",
    ")\n",
    "\n",
    "bedrock_llm = ChatBedrockConverse(\n",
    "    client=session.client(\"bedrock-runtime\"),\n",
    "    region_name=\"eu-west-3\",\n",
    "    model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    base_url=\"https://bedrock-runtime.eu-west-3.amazonaws.com\",\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "bedrock_embeddings = BedrockEmbeddings(\n",
    "    client=session.client(\"bedrock-runtime\"),\n",
    "    model_id=\"cohere.embed-multilingual-v3\",\n",
    "    region_name=\"eu-west-3\",\n",
    ")\n",
    "\n",
    "\n",
    "bedrock_llm = LangchainLLMWrapper(bedrock_llm)\n",
    "bedrock_embeddings = LangchainEmbeddingsWrapper(bedrock_embeddings)\n",
    "\n",
    "\n",
    "class RagasMetric(TypedDict):\n",
    "    function: Callable\n",
    "    category: str\n",
    "    metric_type: str\n",
    "\n",
    "\n",
    "ragas_metrics = {\n",
    "    Faithfulness.name: RagasMetric(\n",
    "        function=Faithfulness(llm=bedrock_llm), category=\"prod\", metric_type=\"score\"\n",
    "    ),\n",
    "    ResponseRelevancy.name: RagasMetric(\n",
    "        function=ResponseRelevancy(llm=bedrock_llm),\n",
    "        category=\"prod\",\n",
    "        metric_type=\"score\",\n",
    "    ),\n",
    "    LLMContextPrecisionWithReference.name: RagasMetric(\n",
    "        function=LLMContextPrecisionWithReference(llm=bedrock_llm),\n",
    "        category=\"dev\",\n",
    "        metric_type=\"score\",\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize an `EvaluationData` class where we'll save our inference results to later evaluate on. We want to keep track of question, answer, and contexts as inputs to the RAGAS evaluations.\n",
    "\n",
    "We also track\n",
    "\n",
    "1. An exported span so we can tie each evaluation to a specific run of our RAG workflow\n",
    "2. Tags on our evaluations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationData(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "    contexts: list[str]\n",
    "    tags: dict[str, str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following `run_simulation` function will take a list of evaluation questions and run our RAG app using the specified RAG configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(\n",
    "    questions,\n",
    "    ground_truths,\n",
    "    retrievers=[base_retriever, recursive_retriever],\n",
    "    response_modes=[\"compact\"],\n",
    "):\n",
    "\n",
    "    simulation_results = []\n",
    "\n",
    "    for mode in response_modes:\n",
    "\n",
    "        response_synthesizer = response_synthesizer_compact\n",
    "\n",
    "        for retrieval_strategy in retrievers:\n",
    "\n",
    "            for question, ground_truth in tqdm(\n",
    "                zip(questions, ground_truths), total=len(questions)\n",
    "            ):\n",
    "\n",
    "                answer = ask_docs(\n",
    "                    question,\n",
    "                    retriever=retrieval_strategy,\n",
    "                    response_synthesizer=response_synthesizer,\n",
    "                )\n",
    "\n",
    "                simulation_results.append(\n",
    "                    EvaluationData(\n",
    "                        question=question,\n",
    "                        answer=str(answer),\n",
    "                        ground_truth=ground_truth,\n",
    "                        contexts=[r.text for r in answer.source_nodes],\n",
    "                        tags={\n",
    "                            \"retriever\": (\n",
    "                                \"recursive\"\n",
    "                                if retrieval_strategy == recursive_retriever\n",
    "                                else \"base\"\n",
    "                            ),\n",
    "                            \"response_mode\": mode,\n",
    "                            \"top_k\": TOP_K,\n",
    "                        },\n",
    "                    )\n",
    "                )\n",
    "    return simulation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the evaluation results using both our baseline and recursive retriever.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:12<00:00,  2.05s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: How do I get started?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: 0a4c6d07-6edc-4cab-ad57-7b00351cc3be\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id 0a4c6d07-6edc-4cab-ad57-7b00351cc3be: How do I get started?\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:02<00:12,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: I have a complex chatbot, what root span should I use to represent this bot?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: 9eaaa384-9bc0-4cef-a5c9-15b6f0642f95\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id 9eaaa384-9bc0-4cef-a5c9-15b6f0642f95: I have a complex chatbot, what root span should I use to represent this bot?\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:04<00:07,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: I have a summarization LLM service with some simple pre-and-post processing steps, what root span should I use to represent this bot?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: 9eaaa384-9bc0-4cef-a5c9-15b6f0642f95\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id 9eaaa384-9bc0-4cef-a5c9-15b6f0642f95: I have a summarization LLM service with some simple pre-and-post processing steps, what root span should I use to represent this bot?\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:05<00:05,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: I don't want to manually instrument my app. Can I still use LLM Observability?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: abe0488f-94a5-41fc-ab4a-6b22f5d7faf3\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id abe0488f-94a5-41fc-ab4a-6b22f5d7faf3: I don't want to manually instrument my app. Can I still use LLM Observability?\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:07<00:03,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: What's the ml app tag?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: 3bbdaa37-cae0-4811-9b36-7e39f1cb9889\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id 3bbdaa37-cae0-4811-9b36-7e39f1cb9889: What's the ml app tag?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: 1c267193-f227-46b1-ad98-75d370193ed2\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id 1c267193-f227-46b1-ad98-75d370193ed2: What's the ml app tag?\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:08<00:01,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: How can I enable user session tracking?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: 3bbdaa37-cae0-4811-9b36-7e39f1cb9889\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id 3bbdaa37-cae0-4811-9b36-7e39f1cb9889: How can I enable user session tracking?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: abe0488f-94a5-41fc-ab4a-6b22f5d7faf3\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id abe0488f-94a5-41fc-ab4a-6b22f5d7faf3: How can I enable user session tracking?\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:10<00:00,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluation_data = run_simulation(\n",
    "    eval_questions, eval_ground_truths, retrievers=[base_retriever, recursive_retriever]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to run RAGAS evaluations and submit the evaluations to Datadog\n",
    "\n",
    "We use the `submit_evaluation` function to send custom evaluation metric data to Datadog.\n",
    "\n",
    "1. Since each evaluation is tied to a span, we used the exported span returned from the earlier function call and pass that into `submit_evaluation`.\n",
    "2. You have to specify the metric type as `score` or `categorical` for each metric you submit to Datadog. So far, all the RAGAS metrics we've used are `score` metrics. However, RAGAS [aspect critiques](https://docs.ragas.io/en/stable/concepts/metrics/critique.html) would be submitted as categorical type evaluation metrics.\n",
    "3. We also tag our evaluation metric with some metadata about the RAG strategy and metric category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def run_ragas(evaluation_data, ragas_metrics):\n",
    "    \"\"\"\n",
    "    Run Ragas evaluation and generate a comprehensive summary DataFrame.\n",
    "\n",
    "    Args:\n",
    "        evaluation_data (list): List of evaluation data dictionaries\n",
    "        ragas_metrics (dict): Dictionary of Ragas metrics to evaluate\n",
    "\n",
    "    Returns:\n",
    "        tuple: A pair of pandas DataFrames (detailed metrics, aggregated metrics)\n",
    "    \"\"\"\n",
    "    # Initialize lists to collect metric results\n",
    "    results_list = []\n",
    "\n",
    "    for span_data in tqdm(evaluation_data, desc=\"Running Ragas Evaluation\"):\n",
    "        # Prepare input dataset\n",
    "        ragas_input = Dataset.from_dict(\n",
    "            {\n",
    "                \"question\": [span_data[\"question\"]],\n",
    "                \"answer\": [span_data[\"answer\"]],\n",
    "                \"contexts\": [span_data[\"contexts\"]],\n",
    "                \"ground_truth\": [span_data.get(\"ground_truth\", \"\")],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Evaluate metrics\n",
    "        results = evaluate(\n",
    "            ragas_input,\n",
    "            [metric[\"function\"] for metric in ragas_metrics.values()],\n",
    "            llm=bedrock_llm,\n",
    "            embeddings=bedrock_embeddings,\n",
    "        )\n",
    "\n",
    "        # Convert results to dictionary\n",
    "        results_df = results.to_pandas().to_dict(\"index\")[0]\n",
    "\n",
    "        # Prepare a dictionary to store metric results\n",
    "        metrics_row = {\n",
    "            \"question\": span_data[\"question\"],\n",
    "            \"retriever\": span_data[\"tags\"][\"retriever\"],\n",
    "            \"response_mode\": span_data[\"tags\"][\"response_mode\"],\n",
    "            \"top_k\": span_data[\"tags\"][\"top_k\"],\n",
    "        }\n",
    "\n",
    "        # Collect non-NaN metrics\n",
    "        for metric_name, metric_config in ragas_metrics.items():\n",
    "            metric_val = results_df[metric_name]\n",
    "            if not math.isnan(metric_val):\n",
    "                metrics_row[metric_name] = metric_val\n",
    "                metrics_row[f\"{metric_name}_category\"] = metric_config[\"category\"]\n",
    "                metrics_row[f\"{metric_name}_type\"] = metric_config[\"metric_type\"]\n",
    "\n",
    "        results_list.append(metrics_row)\n",
    "\n",
    "    # Create a DataFrame from the collected results\n",
    "    summary_df = pd.DataFrame(results_list)\n",
    "\n",
    "    # Compute overall summary statistics\n",
    "    aggregation_columns = [\"retriever\", \"response_mode\", \"top_k\"]\n",
    "    metric_columns = [col for col in summary_df.columns if col in ragas_metrics.keys()]\n",
    "\n",
    "    summary_stats = summary_df.groupby(aggregation_columns)[metric_columns].agg(\n",
    "        [\"mean\", \"std\"]\n",
    "    )\n",
    "\n",
    "    return summary_df, summary_stats\n",
    "\n",
    "\n",
    "# Optional: Enhanced display function for better readability\n",
    "def display_ragas_results(summary_df, summary_stats):\n",
    "    \"\"\"\n",
    "    Print Ragas evaluation results in a formatted manner.\n",
    "\n",
    "    Args:\n",
    "        summary_df (pd.DataFrame): Detailed metrics DataFrame\n",
    "        summary_stats (pd.DataFrame): Aggregated metrics DataFrame\n",
    "    \"\"\"\n",
    "    print(\"Detailed Metrics:\")\n",
    "    print(summary_df)\n",
    "    print(\"\\nAggregated Metrics:\")\n",
    "    print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3/3 [00:33<00:00, 11.06s/it] ?it/s]\n",
      "Evaluating: 100%|██████████| 3/3 [01:18<00:00, 26.00s/it]:11, 33.76s/it]\n",
      "Evaluating: 100%|██████████| 3/3 [01:26<00:00, 28.80s/it]:01, 60.12s/it]\n",
      "Evaluating: 100%|██████████| 3/3 [01:22<00:00, 27.53s/it]:52, 72.49s/it]\n",
      "Evaluating: 100%|██████████| 3/3 [01:20<00:00, 26.97s/it]:13, 76.65s/it]\n",
      "Evaluating: 100%|██████████| 3/3 [01:39<00:00, 33.08s/it]:08, 78.36s/it]\n",
      "Evaluating: 100%|██████████| 3/3 [00:55<00:00, 18.63s/it]:33, 85.62s/it]\n",
      "Evaluating: 100%|██████████| 3/3 [01:29<00:00, 29.82s/it]:20, 76.08s/it]\n",
      "Evaluating: 100%|██████████| 3/3 [01:53<00:00, 37.95s/it]:21, 80.47s/it]\n",
      "Evaluating: 100%|██████████| 3/3 [00:21<00:00,  7.02s/it]:33, 91.03s/it]\n",
      "Evaluating: 100%|██████████| 3/3 [01:24<00:00, 28.22s/it]2:19, 69.60s/it]\n",
      "Evaluating: 100%|██████████| 3/3 [01:25<00:00, 28.45s/it]1:14, 74.38s/it]\n",
      "Running Ragas Evaluation: 100%|██████████| 12/12 [15:16<00:00, 76.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Metrics:\n",
      "                                             question  retriever  \\\n",
      "0                               How do I get started?       base   \n",
      "1   I have a complex chatbot, what root span shoul...       base   \n",
      "2   I have a summarization LLM service with some s...       base   \n",
      "3   I don't want to manually instrument my app. Ca...       base   \n",
      "4                              What's the ml app tag?       base   \n",
      "5             How can I enable user session tracking?       base   \n",
      "6                               How do I get started?  recursive   \n",
      "7   I have a complex chatbot, what root span shoul...  recursive   \n",
      "8   I have a summarization LLM service with some s...  recursive   \n",
      "9   I don't want to manually instrument my app. Ca...  recursive   \n",
      "10                             What's the ml app tag?  recursive   \n",
      "11            How can I enable user session tracking?  recursive   \n",
      "\n",
      "   response_mode  top_k  faithfulness faithfulness_category faithfulness_type  \\\n",
      "0        compact      2      1.000000                  prod             score   \n",
      "1        compact      2      0.800000                  prod             score   \n",
      "2        compact      2      1.000000                  prod             score   \n",
      "3        compact      2      0.333333                  prod             score   \n",
      "4        compact      2      1.000000                  prod             score   \n",
      "5        compact      2      1.000000                  prod             score   \n",
      "6        compact      2      1.000000                  prod             score   \n",
      "7        compact      2      1.000000                  prod             score   \n",
      "8        compact      2      1.000000                  prod             score   \n",
      "9        compact      2      0.333333                  prod             score   \n",
      "10       compact      2      1.000000                  prod             score   \n",
      "11       compact      2      1.000000                  prod             score   \n",
      "\n",
      "    answer_relevancy answer_relevancy_category answer_relevancy_type  \\\n",
      "0           0.614482                      prod                 score   \n",
      "1           0.949906                      prod                 score   \n",
      "2           0.733012                      prod                 score   \n",
      "3           0.923667                      prod                 score   \n",
      "4           0.942968                      prod                 score   \n",
      "5           0.000000                      prod                 score   \n",
      "6           0.743922                      prod                 score   \n",
      "7           0.932833                      prod                 score   \n",
      "8           0.881545                      prod                 score   \n",
      "9           0.923667                      prod                 score   \n",
      "10          0.894909                      prod                 score   \n",
      "11          0.000000                      prod                 score   \n",
      "\n",
      "    llm_context_precision_with_reference  \\\n",
      "0                                    1.0   \n",
      "1                                    0.0   \n",
      "2                                    0.5   \n",
      "3                                    0.0   \n",
      "4                                    0.0   \n",
      "5                                    0.0   \n",
      "6                                    1.0   \n",
      "7                                    0.0   \n",
      "8                                    1.0   \n",
      "9                                    0.0   \n",
      "10                                   1.0   \n",
      "11                                   0.0   \n",
      "\n",
      "   llm_context_precision_with_reference_category  \\\n",
      "0                                            dev   \n",
      "1                                            dev   \n",
      "2                                            dev   \n",
      "3                                            dev   \n",
      "4                                            dev   \n",
      "5                                            dev   \n",
      "6                                            dev   \n",
      "7                                            dev   \n",
      "8                                            dev   \n",
      "9                                            dev   \n",
      "10                                           dev   \n",
      "11                                           dev   \n",
      "\n",
      "   llm_context_precision_with_reference_type  \n",
      "0                                      score  \n",
      "1                                      score  \n",
      "2                                      score  \n",
      "3                                      score  \n",
      "4                                      score  \n",
      "5                                      score  \n",
      "6                                      score  \n",
      "7                                      score  \n",
      "8                                      score  \n",
      "9                                      score  \n",
      "10                                     score  \n",
      "11                                     score  \n",
      "\n",
      "Aggregated Metrics:\n",
      "                              faithfulness           answer_relevancy  \\\n",
      "                                      mean       std             mean   \n",
      "retriever response_mode top_k                                           \n",
      "base      compact       2         0.855556  0.268052         0.694006   \n",
      "recursive compact       2         0.888889  0.272166         0.729479   \n",
      "\n",
      "                                        llm_context_precision_with_reference  \\\n",
      "                                    std                                 mean   \n",
      "retriever response_mode top_k                                                  \n",
      "base      compact       2      0.365978                                 0.25   \n",
      "recursive compact       2      0.363841                                 0.50   \n",
      "\n",
      "                                         \n",
      "                                    std  \n",
      "retriever response_mode top_k            \n",
      "base      compact       2      0.418330  \n",
      "recursive compact       2      0.547723  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "full_metrics_df, aggregated_metrics_df = run_ragas(evaluation_data, ragas_metrics)\n",
    "display_ragas_results(full_metrics_df, aggregated_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
